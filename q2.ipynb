{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc5a724",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Habilitando Mixed Precision para acelerar o treinamento...\n",
      "Política de precisão global definida.\n",
      "\n",
      "Iniciando treinamento do modelo (versão para dataset com máscaras)...\n",
      "Encontrados 735 pares de imagens válidos (com e sem máscara).\n",
      "Total de Imagens no Dataset: 5000, Passos por Época: 312\n",
      "Epoch 1/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1545s\u001b[0m 5s/step - loss: 0.7697\n",
      "Epoch 2/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1256s\u001b[0m 4s/step - loss: 0.5125\n",
      "Epoch 3/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1016s\u001b[0m 3s/step - loss: 0.5172\n",
      "Epoch 4/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1049s\u001b[0m 3s/step - loss: 0.4707\n",
      "Epoch 5/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m934s\u001b[0m 3s/step - loss: 0.4249\n",
      "Epoch 6/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m880s\u001b[0m 3s/step - loss: 0.3720\n",
      "Epoch 7/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m824s\u001b[0m 3s/step - loss: 0.3176\n",
      "Epoch 8/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 3s/step - loss: 0.2896\n",
      "Epoch 9/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m811s\u001b[0m 3s/step - loss: 0.2616\n",
      "Epoch 10/10\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m806s\u001b[0m 3s/step - loss: 0.2122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo de embedding salvo como 'face_embedding_model_masked.h5'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 128), dtype=float32, sparse=False, ragged=False, name=keras_tensor_981>',)\n  • kwargs={'mask': 'None'}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 336\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# --- ETAPA 2: CRIAÇÃO/CARREGAMENTO DO BANCO DE DADOS ---\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(MODEL_FILENAME):\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     face_system = \u001b[43mFaceRecognitionSystem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODEL_FILENAME\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(DB_FILENAME):\n\u001b[32m    339\u001b[39m          \u001b[38;5;66;03m# A criação do banco de dados depende do dataset original\u001b[39;00m\n\u001b[32m    340\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.exists(os.path.join(DATASET_PATH, \u001b[33m\"\u001b[39m\u001b[33mWithoutMask\u001b[39m\u001b[33m\"\u001b[39m)):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 193\u001b[39m, in \u001b[36mFaceRecognitionSystem.__init__\u001b[39m\u001b[34m(self, model_path, img_size)\u001b[39m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n\u001b[32m--> \u001b[39m\u001b[32m193\u001b[39m     \u001b[38;5;28mself\u001b[39m.embedding_model = \u001b[43mkeras\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtriplet_loss\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtriplet_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    194\u001b[39m     \u001b[38;5;28mself\u001b[39m.img_size = img_size\n\u001b[32m    195\u001b[39m     \u001b[38;5;28mself\u001b[39m.database = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(filepath, custom_objects, compile, safe_mode)\u001b[39m\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib.load_model(\n\u001b[32m    190\u001b[39m         filepath,\n\u001b[32m    191\u001b[39m         custom_objects=custom_objects,\n\u001b[32m    192\u001b[39m         \u001b[38;5;28mcompile\u001b[39m=\u001b[38;5;28mcompile\u001b[39m,\n\u001b[32m    193\u001b[39m         safe_mode=safe_mode,\n\u001b[32m    194\u001b[39m     )\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith((\u001b[33m\"\u001b[39m\u001b[33m.h5\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m.hdf5\u001b[39m\u001b[33m\"\u001b[39m)):\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath).endswith(\u001b[33m\"\u001b[39m\u001b[33m.keras\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    201\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    202\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    203\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mzip file.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:133\u001b[39m, in \u001b[36mload_model_from_hdf5\u001b[39m\u001b[34m(filepath, custom_objects, compile)\u001b[39m\n\u001b[32m    130\u001b[39m model_config = json_utils.decode(model_config)\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m saving_options.keras_option_scope(use_legacy_config=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     model = \u001b[43msaving_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m     \u001b[38;5;66;03m# set weights\u001b[39;00m\n\u001b[32m    138\u001b[39m     load_weights_from_hdf5_group(f[\u001b[33m\"\u001b[39m\u001b[33mmodel_weights\u001b[39m\u001b[33m\"\u001b[39m], model)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\legacy\\saving\\saving_utils.py:88\u001b[39m, in \u001b[36mmodel_from_config\u001b[39m\u001b[34m(config, custom_objects)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# TODO(nkovela): Swap find and replace args during Keras 3.0 release\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Replace keras refs with keras\u001b[39;00m\n\u001b[32m     86\u001b[39m config = _find_replace_nested_dict(config, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mserialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeserialize_keras_object\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodule_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMODULE_OBJECTS\u001b[49m\u001b[43m.\u001b[49m\u001b[43mALL_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprintable_module_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlayer\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\legacy\\saving\\serialization.py:495\u001b[39m, in \u001b[36mdeserialize_keras_object\u001b[39m\u001b[34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[39m\n\u001b[32m    490\u001b[39m cls_config = _find_replace_nested_dict(\n\u001b[32m    491\u001b[39m     cls_config, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mkeras.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    492\u001b[39m )\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mcustom_objects\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m arg_spec.args:\n\u001b[32m--> \u001b[39m\u001b[32m495\u001b[39m     deserialized_obj = \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfrom_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcls_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mobject_registration\u001b[49m\u001b[43m.\u001b[49m\u001b[43mGLOBAL_CUSTOM_OBJECTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m object_registration.CustomObjectScope(custom_objects):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\models\\model.py:651\u001b[39m, in \u001b[36mModel.from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_functional_config \u001b[38;5;129;01mand\u001b[39;00m revivable_as_functional:\n\u001b[32m    647\u001b[39m     \u001b[38;5;66;03m# Revive Functional model\u001b[39;00m\n\u001b[32m    648\u001b[39m     \u001b[38;5;66;03m# (but not Functional subclasses with a custom __init__)\u001b[39;00m\n\u001b[32m    649\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m functional_from_config\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunctional_from_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_objects\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[38;5;66;03m# Either the model has a custom __init__, or the config\u001b[39;00m\n\u001b[32m    656\u001b[39m \u001b[38;5;66;03m# does not contain all the information necessary to\u001b[39;00m\n\u001b[32m    657\u001b[39m \u001b[38;5;66;03m# revive a Functional model. This happens when the user creates\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    660\u001b[39m \u001b[38;5;66;03m# In this case, we fall back to provide all config into the\u001b[39;00m\n\u001b[32m    661\u001b[39m \u001b[38;5;66;03m# constructor of the class.\u001b[39;00m\n\u001b[32m    662\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\models\\functional.py:579\u001b[39m, in \u001b[36mfunctional_from_config\u001b[39m\u001b[34m(cls, config, custom_objects)\u001b[39m\n\u001b[32m    577\u001b[39m node_data = node_data_list[node_index]\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m579\u001b[39m     \u001b[43mprocess_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# If the node does not have all inbound layers\u001b[39;00m\n\u001b[32m    582\u001b[39m \u001b[38;5;66;03m# available, stop processing and continue later\u001b[39;00m\n\u001b[32m    583\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\models\\functional.py:509\u001b[39m, in \u001b[36mfunctional_from_config.<locals>.process_node\u001b[39m\u001b[34m(layer, node_data)\u001b[39m\n\u001b[32m    506\u001b[39m args, kwargs = deserialize_node(node_data, created_layers)\n\u001b[32m    507\u001b[39m \u001b[38;5;66;03m# Call layer on its inputs, thus creating the node\u001b[39;00m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# and building the layer if needed.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m509\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\lambda_layer.py:95\u001b[39m, in \u001b[36mLambda.compute_output_shape\u001b[39m\u001b[34m(self, input_shape)\u001b[39m\n\u001b[32m     93\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m tree.map_structure(\u001b[38;5;28;01mlambda\u001b[39;00m x: x.shape, output_spec)\n\u001b[32m     94\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m     96\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mWe could not automatically infer the shape of \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     97\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mthe Lambda\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms output. Please specify the `output_shape` \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     98\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33margument for this Lambda layer.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     99\u001b[39m         )\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m._output_shape):\n\u001b[32m    102\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._output_shape(input_shape)\n",
      "\u001b[31mNotImplementedError\u001b[39m: Exception encountered when calling Lambda.call().\n\n\u001b[1mWe could not automatically infer the shape of the Lambda's output. Please specify the `output_shape` argument for this Lambda layer.\u001b[0m\n\nArguments received by Lambda.call():\n  • args=('<KerasTensor shape=(None, 128), dtype=float32, sparse=False, ragged=False, name=keras_tensor_981>',)\n  • kwargs={'mask': 'None'}"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial.distance import cosine\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DATASET_PATH = r\"C:\\Users\\ResTIC16\\OneDrive\\Desktop\\dtlas\"\n",
    "\n",
    "\n",
    "# --- OTIMIZAÇÕES APLICADAS ---\n",
    "IMG_HEIGHT = 96\n",
    "IMG_WIDTH = 96\n",
    "EMBEDDING_DIM = 128\n",
    "MARGIN = 1.0\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 10\n",
    "# -----------------------------\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "# --- 2. GERADOR DE DADOS OTIMIZADO (MODIFICADO) ---\n",
    "\n",
    "def create_optimized_triplet_dataset(dataset_path, batch_size):\n",
    "    \"\"\"\n",
    "    Cria um pipeline tf.data para o dataset WithMask/WithoutMask.\n",
    "    \"\"\"\n",
    "    path_with_mask = os.path.join(dataset_path, \"WithMask\")\n",
    "    path_without_mask = os.path.join(dataset_path, \"WithoutMask\")\n",
    "\n",
    "    if not os.path.exists(path_with_mask) or not os.path.exists(path_without_mask):\n",
    "        raise FileNotFoundError(\n",
    "            f\"As pastas 'WithMask' e 'WithoutMask' não foram encontradas em '{dataset_path}'.\\n\"\n",
    "            \"Verifique a estrutura do seu diretório e o caminho fornecido.\"\n",
    "        )\n",
    "\n",
    "    # Mapeia cada identidade (ID da pessoa) aos seus respectivos caminhos de imagem\n",
    "    pessoas_map = {}\n",
    "    total_images = 0\n",
    "    \n",
    "    # Processa a pasta WithMask\n",
    "    for img_file in os.listdir(path_with_mask):\n",
    "        pessoa_id = img_file.split('_')[0] # Extrai o ID da pessoa do nome do arquivo (ex: '00001')\n",
    "        if pessoa_id not in pessoas_map:\n",
    "            pessoas_map[pessoa_id] = {}\n",
    "        pessoas_map[pessoa_id]['masked'] = os.path.join(path_with_mask, img_file)\n",
    "        total_images += 1\n",
    "\n",
    "    # Processa a pasta WithoutMask\n",
    "    for img_file in os.listdir(path_without_mask):\n",
    "        pessoa_id = img_file.split('_')[0]\n",
    "        if pessoa_id in pessoas_map: # Apenas considera pessoas que têm par com máscara\n",
    "            pessoas_map[pessoa_id]['unmasked'] = os.path.join(path_without_mask, img_file)\n",
    "\n",
    "    # Filtra o dicionário para garantir que cada pessoa tenha ambas as imagens (com e sem máscara)\n",
    "    valid_pairs = {pid: paths for pid, paths in pessoas_map.items() if 'masked' in paths and 'unmasked' in paths}\n",
    "    pessoa_list = list(valid_pairs.keys())\n",
    "\n",
    "    if not pessoa_list:\n",
    "        raise ValueError(\"Nenhum par de imagens (com/sem máscara) foi encontrado. Verifique os nomes dos arquivos.\")\n",
    "\n",
    "    print(f\"Encontrados {len(valid_pairs)} pares de imagens válidos (com e sem máscara).\")\n",
    "    \n",
    "    def triplet_generator():\n",
    "        \"\"\"Gerador Python que produz triplets (âncora, positivo, negativo).\"\"\"\n",
    "        while True:\n",
    "            # 1. Escolhe uma pessoa para ser âncora e positiva\n",
    "            pessoa_anc_pos_id = random.choice(pessoa_list)\n",
    "            \n",
    "            # 2. Escolhe uma pessoa diferente para ser a negativa\n",
    "            pessoa_neg_id_list = [p for p in pessoa_list if p != pessoa_anc_pos_id]\n",
    "            if not pessoa_neg_id_list:\n",
    "                continue # Pula caso haja apenas uma pessoa\n",
    "            pessoa_neg_id = random.choice(pessoa_neg_id_list)\n",
    "            \n",
    "            # 3. Define os caminhos de âncora e positivo da mesma pessoa\n",
    "            #    Alterna aleatoriamente se a âncora é com ou sem máscara\n",
    "            if random.random() > 0.5:\n",
    "                ancora_path = valid_pairs[pessoa_anc_pos_id]['masked']\n",
    "                positiva_path = valid_pairs[pessoa_anc_pos_id]['unmasked']\n",
    "            else:\n",
    "                ancora_path = valid_pairs[pessoa_anc_pos_id]['unmasked']\n",
    "                positiva_path = valid_pairs[pessoa_anc_pos_id]['masked']\n",
    "\n",
    "            # 4. Define o caminho negativo de uma pessoa diferente\n",
    "            #    A imagem negativa também pode ser com ou sem máscara\n",
    "            if random.random() > 0.5:\n",
    "                negativa_path = valid_pairs[pessoa_neg_id]['masked']\n",
    "            else:\n",
    "                negativa_path = valid_pairs[pessoa_neg_id]['unmasked']\n",
    "\n",
    "            yield ancora_path, positiva_path, negativa_path\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "        triplet_generator,\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "            tf.TensorSpec(shape=(), dtype=tf.string)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def _load_and_preprocess_image(img_path):\n",
    "        img = tf.io.read_file(img_path)\n",
    "        img = tf.image.decode_jpeg(img, channels=3)\n",
    "        img = tf.image.resize(img, [IMG_HEIGHT, IMG_WIDTH])\n",
    "        img = img / 255.0\n",
    "        return img\n",
    "\n",
    "    def load_triplet_images(anc_path, pos_path, neg_path):\n",
    "        return (\n",
    "            _load_and_preprocess_image(anc_path),\n",
    "            _load_and_preprocess_image(pos_path),\n",
    "            _load_and_preprocess_image(neg_path)\n",
    "        )\n",
    "\n",
    "    dataset = dataset.map(load_triplet_images, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    def format_dataset_entry(anc_img, pos_img, neg_img):\n",
    "        return {\"anchor_input\": anc_img, \"positive_input\": pos_img, \"negative_input\": neg_img}, tf.zeros(())\n",
    "\n",
    "    dataset = dataset.map(format_dataset_entry, num_parallel_calls=AUTOTUNE)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return dataset, total_images\n",
    "\n",
    "\n",
    "# --- 3. CRIAÇÃO DO MODELO (Sem alterações) ---\n",
    "\n",
    "def create_embedding_network(embedding_dim=EMBEDDING_DIM):\n",
    "    \"\"\"Cria a rede neural que gera os vetores (embeddings).\"\"\"\n",
    "    base_model = keras.applications.MobileNetV2(\n",
    "        input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),\n",
    "        include_top=False,\n",
    "        weights='imagenet',\n",
    "        alpha=0.35\n",
    "    )\n",
    "    base_model.trainable = True\n",
    "    inputs = keras.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "    x = base_model(inputs, training=True)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    x = layers.Dense(embedding_dim, dtype='float32')(x)\n",
    "    embeddings = layers.Lambda(lambda t: tf.nn.l2_normalize(t, axis=1), name=\"L2_Normalization\", dtype='float32')(x)\n",
    "    return keras.Model(inputs, embeddings, name=\"EmbeddingNet\")\n",
    "\n",
    "def triplet_loss(y_true, y_pred, margin=MARGIN):\n",
    "    \"\"\"Calcula a Triplet Loss.\"\"\"\n",
    "    anchor, positive, negative = y_pred[:, :EMBEDDING_DIM], y_pred[:, EMBEDDING_DIM:2*EMBEDDING_DIM], y_pred[:, 2*EMBEDDING_DIM:]\n",
    "    pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=1)\n",
    "    neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=1)\n",
    "    loss = tf.maximum(pos_dist - neg_dist + margin, 0.0)\n",
    "    return tf.reduce_mean(loss)\n",
    "\n",
    "class TripletModel(keras.Model):\n",
    "    \"\"\"Modelo customizado que encapsula a rede e a lógica de treinamento.\"\"\"\n",
    "    def __init__(self, embedding_net, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embedding_net = embedding_net\n",
    "\n",
    "    def call(self, inputs):\n",
    "        anchor_embedding = self.embedding_net(inputs[\"anchor_input\"])\n",
    "        positive_embedding = self.embedding_net(inputs[\"positive_input\"])\n",
    "        negative_embedding = self.embedding_net(inputs[\"negative_input\"])\n",
    "        return tf.concat([anchor_embedding, positive_embedding, negative_embedding], axis=1)\n",
    "\n",
    "\n",
    "# --- 4. SISTEMA DE RECONHECIMENTO FACIAL (MODIFICADO) ---\n",
    "\n",
    "class FaceRecognitionSystem:\n",
    "    def __init__(self, model_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "        self.embedding_model = keras.models.load_model(model_path, custom_objects={\"triplet_loss\": triplet_loss})\n",
    "        self.img_size = img_size\n",
    "        self.database = {}\n",
    "\n",
    "    def _preprocess_image(self, img_path):\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None: return None\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = cv.resize(img, self.img_size)\n",
    "        img = img.astype(np.float32) / 255.0\n",
    "        return img\n",
    "\n",
    "    def create_database(self, dataset_path, batch_size=32):\n",
    "        \"\"\"\n",
    "        Função modificada para criar o banco de dados a partir das imagens SEM MÁSCARA.\n",
    "        O vetor médio será calculado usando apenas as imagens da pasta 'WithoutMask'\n",
    "        para ter uma representação \"limpa\" da face.\n",
    "        \"\"\"\n",
    "        print(\"Criando banco de dados de embeddings (usando apenas imagens 'WithoutMask')...\")\n",
    "        path_without_mask = os.path.join(dataset_path, \"WithoutMask\")\n",
    "        \n",
    "        if not os.path.exists(path_without_mask):\n",
    "             raise FileNotFoundError(f\"Pasta 'WithoutMask' não encontrada em: {dataset_path}\")\n",
    "\n",
    "        image_paths = [os.path.join(path_without_mask, f) for f in os.listdir(path_without_mask)]\n",
    "        if not image_paths:\n",
    "            print(\"Nenhuma imagem encontrada na pasta 'WithoutMask'.\")\n",
    "            return\n",
    "\n",
    "        # Para esta estrutura, o \"nome da pessoa\" é o ID extraído do arquivo\n",
    "        # Agrupamos todas as imagens por ID de pessoa\n",
    "        person_images = {}\n",
    "        for img_path in image_paths:\n",
    "            person_id = os.path.basename(img_path).split('_')[0]\n",
    "            if person_id not in person_images:\n",
    "                person_images[person_id] = []\n",
    "            person_images[person_id].append(img_path)\n",
    "\n",
    "        for person_id, paths in sorted(person_images.items()):\n",
    "            processed_images_batch = [self._preprocess_image(p) for p in paths if self._preprocess_image(p) is not None]\n",
    "            if not processed_images_batch: continue\n",
    "\n",
    "            img_array = np.array(processed_images_batch)\n",
    "            embeddings = self.embedding_model.predict(img_array, batch_size=batch_size, verbose=0)\n",
    "            \n",
    "            # Usamos a média dos embeddings das imagens sem máscara para representar a pessoa\n",
    "            self.database[person_id] = np.mean(embeddings, axis=0)\n",
    "            print(f\"-> Vetor médio criado para a pessoa ID: {person_id}\")\n",
    "\n",
    "        print(\"Banco de dados criado com sucesso!\")\n",
    "\n",
    "\n",
    "    def recognize_face(self, img_path, threshold=0.7):\n",
    "        if not self.database:\n",
    "            print(\"Erro: Banco de dados está vazio.\")\n",
    "            return \"Desconhecido\", 0.0\n",
    "\n",
    "        processed_img = self._preprocess_image(img_path)\n",
    "        if processed_img is None:\n",
    "            return \"Erro ao ler imagem\", 0.0\n",
    "\n",
    "        unknown_embedding = self.embedding_model.predict(np.expand_dims(processed_img, axis=0), verbose=0)[0]\n",
    "\n",
    "        min_dist = float(\"inf\")\n",
    "        recognized_id = \"Desconhecido\"\n",
    "        for person_id, db_embedding in self.database.items():\n",
    "            dist = cosine(unknown_embedding, db_embedding)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                recognized_id = person_id\n",
    "\n",
    "        if min_dist > threshold:\n",
    "            recognized_id = \"Desconhecido\"\n",
    "            \n",
    "        confidence = (1 - min_dist)\n",
    "        return recognized_id, confidence\n",
    "\n",
    "    def save_database(self, path=\"face_database_masked.npy\"):\n",
    "        np.save(path, self.database)\n",
    "        print(f\"Banco de dados salvo em: {path}\")\n",
    "\n",
    "    def load_database(self, path=\"face_database_masked.npy\"):\n",
    "        if os.path.exists(path):\n",
    "            self.database = np.load(path, allow_pickle=True).item()\n",
    "            print(f\"Banco de dados carregado de: {path}\")\n",
    "        else:\n",
    "            print(f\"Arquivo de banco de dados não encontrado: {path}\")\n",
    "\n",
    "\n",
    "# --- 5. FLUXO PRINCIPAL DE EXECUÇÃO ---\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    MODEL_FILENAME = \"face_embedding_model_masked.h5\"\n",
    "    DB_FILENAME = \"face_database_masked.npy\"\n",
    "\n",
    "    # --- ETAPA 1: TREINAMENTO ---\n",
    "    if not os.path.exists(MODEL_FILENAME):\n",
    "        print(\"Habilitando Mixed Precision para acelerar o treinamento...\")\n",
    "        policy = tf.keras.mixed_precision.Policy('mixed_float16')\n",
    "        tf.keras.mixed_precision.set_global_policy(policy)\n",
    "        print('Política de precisão global definida.')\n",
    "\n",
    "        print(\"\\nIniciando treinamento do modelo (versão para dataset com máscaras)...\")\n",
    "\n",
    "        embedding_net = create_embedding_network()\n",
    "        triplet_model = TripletModel(embedding_net)\n",
    "\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "        optimizer = tf.keras.optimizers.LossScaleOptimizer(optimizer)\n",
    "\n",
    "        triplet_model.compile(optimizer=optimizer, loss=triplet_loss)\n",
    "\n",
    "        try:\n",
    "            train_dataset, num_images = create_optimized_triplet_dataset(DATASET_PATH, BATCH_SIZE)\n",
    "            STEPS_PER_EPOCH = max(1, num_images // BATCH_SIZE)\n",
    "            print(f\"Total de Imagens no Dataset: {num_images}, Passos por Época: {STEPS_PER_EPOCH}\")\n",
    "\n",
    "            history = triplet_model.fit(\n",
    "                train_dataset,\n",
    "                steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                epochs=EPOCHS,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            embedding_net.save(MODEL_FILENAME)\n",
    "            print(f\"Modelo de embedding salvo como '{MODEL_FILENAME}'\")\n",
    "\n",
    "            plt.plot(history.history['loss'])\n",
    "            plt.title('Perda do Modelo (Triplet Loss)')\n",
    "            plt.ylabel('Loss')\n",
    "            plt.xlabel('Época')\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "\n",
    "        except (FileNotFoundError, ValueError) as e:\n",
    "            print(f\"\\nERRO: O treinamento não pôde ser iniciado. Razão: {e}\")\n",
    "            print(\"Por favor, verifique o caminho do dataset e a estrutura das pastas.\")\n",
    "\n",
    "    else:\n",
    "        print(f\"Modelo '{MODEL_FILENAME}' já existe. Pulando treinamento.\")\n",
    "\n",
    "    # --- ETAPA 2: CRIAÇÃO/CARREGAMENTO DO BANCO DE DADOS ---\n",
    "    if os.path.exists(MODEL_FILENAME):\n",
    "        face_system = FaceRecognitionSystem(model_path=MODEL_FILENAME)\n",
    "        \n",
    "        if not os.path.exists(DB_FILENAME):\n",
    "             # A criação do banco de dados depende do dataset original\n",
    "            if os.path.exists(os.path.join(DATASET_PATH, \"WithoutMask\")):\n",
    "                face_system.create_database(DATASET_PATH)\n",
    "                face_system.save_database(DB_FILENAME)\n",
    "            else:\n",
    "                 print(f\"\\nAVISO: Não foi possível criar o banco de dados pois o caminho '{DATASET_PATH}' não contém a pasta 'WithoutMask'.\")\n",
    "        else:\n",
    "            face_system.load_database(DB_FILENAME)\n",
    "    else:\n",
    "        print(\"\\nAVISO: Modelo não encontrado. Pule a criação do banco de dados e o reconhecimento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5e31fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO PROCESSO PARA ID: marcelinho_01 ---\n",
      "ERRO CRÍTICO: Arquivo do banco de dados não encontrado em 'face_database_masked.npy'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO ---\n",
    "# Verifique se estes nomes e caminhos estão corretos\n",
    "MODEL_FILENAME = \"face_embedding_model_masked.h5\"\n",
    "DB_FILENAME = \"face_database_masked.npy\"\n",
    "\n",
    "# Coloque o caminho da imagem da nova pessoa aqui\n",
    "NEW_PERSON_IMAGE_PATH = r\"C:\\Users\\ResTIC16\\OneDrive\\Desktop\\dtlas/marcelinho_no_db.jpg\"\n",
    "\n",
    "# Defina um ID único para a nova pessoa\n",
    "NEW_PERSON_ID = \"marcelinho_01\" \n",
    "\n",
    "# --- 2. DEFINIÇÕES TÉCNICAS (Necessárias para o modelo) ---\n",
    "IMG_WIDTH, IMG_HEIGHT = 96, 96\n",
    "\n",
    "# Camada customizada que precisa ser definida para carregar o modelo\n",
    "class L2Normalization(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.l2_normalize(inputs, axis=1)\n",
    "    def get_config(self):\n",
    "        config = super(L2Normalization, self).get_config()\n",
    "        return config\n",
    "\n",
    "# Função para pré-processar a imagem\n",
    "def preprocess_single_image(img_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img.astype(np.float32) / 255.0\n",
    "\n",
    "# --- 3. FUNÇÃO PRINCIPAL (Lógica organizada) ---\n",
    "def add_or_update_person_in_db(person_id, image_path, model_path, db_path):\n",
    "    \"\"\"\n",
    "    Carrega o modelo e o banco de dados, e adiciona ou atualiza o embedding de uma pessoa.\n",
    "    \"\"\"\n",
    "    print(f\"--- INICIANDO PROCESSO PARA ID: {person_id} ---\")\n",
    "\n",
    "    # Passo 1: Verificar se todos os arquivos necessários existem\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERRO CRÍTICO: Arquivo do modelo não encontrado em '{model_path}'\")\n",
    "        return\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"ERRO CRÍTICO: Arquivo do banco de dados não encontrado em '{db_path}'\")\n",
    "        return\n",
    "    \n",
    "    # Normaliza o caminho da imagem para evitar erros de SO\n",
    "    norm_image_path = os.path.normpath(image_path)\n",
    "    if not os.path.exists(norm_image_path):\n",
    "        print(f\"ERRO CRÍTICO: Imagem da pessoa não encontrada em '{norm_image_path}'\")\n",
    "        return\n",
    "\n",
    "    # Passo 2: Tentar carregar o sistema e processar a imagem\n",
    "    try:\n",
    "        print(\"Carregando modelo e banco de dados existente...\")\n",
    "        embedding_model = keras.models.load_model(model_path, custom_objects={\"L2Normalization\": L2Normalization})\n",
    "        database = np.load(db_path, allow_pickle=True).item()\n",
    "        \n",
    "        if person_id in database:\n",
    "            print(f\"AVISO: O ID '{person_id}' já existe. A entrada será atualizada com a nova imagem.\")\n",
    "\n",
    "        print(f\"Processando nova imagem: {norm_image_path}\")\n",
    "        processed_img = preprocess_single_image(norm_image_path)\n",
    "\n",
    "        if processed_img is None:\n",
    "            print(f\"ERRO: Falha ao ler ou processar a imagem em '{norm_image_path}'.\")\n",
    "            return\n",
    "            \n",
    "        # Passo 3: Gerar embedding, atualizar e salvar\n",
    "        new_embedding = embedding_model.predict(np.expand_dims(processed_img, axis=0), verbose=0)[0]\n",
    "        database[person_id] = new_embedding\n",
    "        np.save(db_path, database)\n",
    "        \n",
    "        print(\"\\n--- SUCESSO! ---\")\n",
    "        print(f\"Pessoa com ID '{person_id}' foi adicionada/atualizada no banco de dados.\")\n",
    "        print(f\"O arquivo '{db_path}' agora contém {len(database)} identidades.\")\n",
    "\n",
    "        # Mostra a imagem adicionada para confirmação\n",
    "        img_to_display = cv2.cvtColor(cv2.imread(norm_image_path), cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_to_display)\n",
    "        plt.title(f\"Imagem Adicionada para o ID: {person_id}\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro inesperado durante a operação: {e}\")\n",
    "\n",
    "# --- 4. EXECUÇÃO ---\n",
    "# Chama a função principal com as configurações definidas no início do script.\n",
    "if __name__ == \"__main__\":\n",
    "    add_or_update_person_in_db(\n",
    "        person_id=NEW_PERSON_ID,\n",
    "        image_path=NEW_PERSON_IMAGE_PATH,\n",
    "        model_path=MODEL_FILENAME,\n",
    "        db_path=DB_FILENAME\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04016d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- INICIANDO RECONHECIMENTO FACIAL ---\n",
      "ERRO: Banco de dados não encontrado em 'face_database_masked.npy'. Execute as etapas anteriores.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from scipy.spatial.distance import cosine\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- 1. CONFIGURAÇÃO ---\n",
    "MODEL_FILENAME = \"face_embedding_model_masked.h5\"\n",
    "DB_FILENAME = \"face_database_masked.npy\"\n",
    "\n",
    "# !!! IMPORTANTE: COLOQUE AQUI O CAMINHO DA IMAGEM DO MARCELINHO COM MÁSCARA !!!\n",
    "IMAGE_TO_RECOGNIZE_PATH = r\"C:\\Caminho\\Para\\Sua\\Imagem\\marcelinho_na_inferencia.jpg\" # <--- ALTERE ESTA LINHA\n",
    "\n",
    "# --- 2. DEFINIÇÕES TÉCNICAS (Necessárias para o modelo) ---\n",
    "IMG_WIDTH, IMG_HEIGHT = 96, 96\n",
    "\n",
    "# Camada customizada que precisa ser definida para carregar o modelo\n",
    "class L2Normalization(layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(L2Normalization, self).__init__(**kwargs)\n",
    "    def call(self, inputs):\n",
    "        return tf.nn.l2_normalize(inputs, axis=1)\n",
    "    def get_config(self):\n",
    "        config = super(L2Normalization, self).get_config()\n",
    "        return config\n",
    "\n",
    "# Função para pré-processar a imagem de entrada\n",
    "def preprocess_single_image(img_path, img_size=(IMG_WIDTH, IMG_HEIGHT)):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Converte para RGB para Matplotlib\n",
    "    img = cv2.resize(img, img_size)\n",
    "    return img.astype(np.float32) / 255.0\n",
    "\n",
    "# --- 3. LÓGICA DE RECONHECIMENTO FACIAL ---\n",
    "def recognize_person(image_path, model_path, db_path, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Carrega o sistema e reconhece uma pessoa em uma única imagem.\n",
    "    \"\"\"\n",
    "    print(\"--- INICIANDO RECONHECIMENTO FACIAL ---\")\n",
    "\n",
    "    # Validar se todos os arquivos necessários existem\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\"ERRO: Modelo não encontrado em '{model_path}'. Execute as etapas anteriores.\")\n",
    "        return\n",
    "    if not os.path.exists(db_path):\n",
    "        print(f\"ERRO: Banco de dados não encontrado em '{db_path}'. Execute as etapas anteriores.\")\n",
    "        return\n",
    "    norm_image_path = os.path.normpath(image_path)\n",
    "    if not os.path.exists(norm_image_path):\n",
    "        print(f\"ERRO: Imagem de teste não encontrada em '{norm_image_path}'. Verifique o caminho.\")\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        # Carregar o modelo e o banco de dados\n",
    "        print(\"Carregando modelo e banco de dados...\")\n",
    "        embedding_model = keras.models.load_model(model_path, custom_objects={\"L2Normalization\": L2Normalization})\n",
    "        database = np.load(db_path, allow_pickle=True).item()\n",
    "        print(f\"Banco de dados carregado com {len(database)} identidades.\")\n",
    "\n",
    "        # Processar a imagem de teste\n",
    "        print(f\"Processando imagem: {norm_image_path}\")\n",
    "        processed_img = preprocess_single_image(norm_image_path)\n",
    "        if processed_img is None:\n",
    "            print(\"ERRO: Falha ao ler a imagem.\")\n",
    "            return\n",
    "\n",
    "        # Gerar o embedding (assinatura facial)\n",
    "        unknown_embedding = embedding_model.predict(np.expand_dims(processed_img, axis=0), verbose=0)[0]\n",
    "\n",
    "        # Comparar com todos no banco de dados\n",
    "        min_dist = float(\"inf\")\n",
    "        recognized_id = \"Desconhecido\"\n",
    "        for person_id, db_embedding in database.items():\n",
    "            dist = cosine(unknown_embedding, db_embedding)\n",
    "            if dist < min_dist:\n",
    "                min_dist = dist\n",
    "                recognized_id = person_id\n",
    "\n",
    "        # Aplicar o limiar de decisão\n",
    "        if min_dist > threshold:\n",
    "            recognized_id = \"Desconhecido\"\n",
    "        confidence = (1 - min_dist)\n",
    "\n",
    "        # Exibir o resultado final\n",
    "        print(\"\\n--- RESULTADO DO RECONHECIMENTO ---\")\n",
    "        print(f\"Pessoa reconhecida como: '{recognized_id}'\")\n",
    "        print(f\"Confiança: {confidence:.2%}\")\n",
    "        print(f\"Distância (similaridade): {min_dist:.4f} (quanto menor, mais similar)\")\n",
    "\n",
    "        img_to_display = cv2.cvtColor(cv2.imread(norm_image_path), cv2.COLOR_BGR2RGB)\n",
    "        plt.imshow(img_to_display)\n",
    "        plt.title(f\"Reconhecido como: {recognized_id} ({confidence:.1%})\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\nOcorreu um erro inesperado: {e}\")\n",
    "\n",
    "# --- 4. EXECUÇÃO ---\n",
    "# Chama a função de reconhecimento com as configurações definidas\n",
    "if __name__ == \"__main__\":\n",
    "    recognize_person(\n",
    "        image_path=IMAGE_TO_RECOGNIZE_PATH,\n",
    "        model_path=MODEL_FILENAME,\n",
    "        db_path=DB_FILENAME\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
